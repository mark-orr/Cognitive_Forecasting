The primary purpose of Study 1 was to understand, in a naturalistic, observational setting, the relation between human predictions of duration and the unobserved prior, given the Bayesian decision model we described in the Introduction.  A principle value of the observational context was that $t_{predicted}$ and $t_{past}$ were not mutually constraining.  We hoped to and did observe cases for which $t_{past}$ approached $t_{predicted}$--the interesting case in terms of the Bayesian prediction model and its relation to human predictions. 

We came to this study without precise predictions, but with bounds on what we expected to see as presented in Figure \ref{fig:PriorShift2Panel}: the invariant prediction and the invariant prior.  Neither was observed.  Instead, our observations were consistent with the notion that the participants were adapting their predictions as the difference between the predicted duration of the epidemic and the prior deviated.  We saw signatures of this in both the aggregate time-series and in the individual-level time series.  The most suggestive result was that presented in Figure \ref{fig:Single_Ss_Summary_2} where we see a clear reduction in the difference between predicted duration and the prior after they deviated a large degree. 

Study 1 presupposes that the Bayesian prediction model operates without knowledge of the difference between $t_{predicted}$ and the expected value of the prior; this kind of comparison is not computed in the model.  So, by claiming that we have provisional evidence for human adaptation, we are also claiming, strictly speaking, that the decision model computes something in relation to this difference.  We leave this for future experimental study in which proper control would be instrumented.

One final comment for discussion.  It is paramount to understand that there is no necessity for the prior to split from the predicted value; the participant can always increase their predicted duration to a value large enough so that the expected value of the prior matches it.  In short, pulling up on the predicted value always works, if you pull hard enough.  We did not see this in these data, but a less severe adaptation.
